# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ezvAzU3ApAMTym-N3td6u7Y2kpXU_HI3
"""

# train.py
import pandas as pd
import numpy as np
import xgboost as xgb
import io

print("--- Starting Model Training ---")

# --- 1. Data Loading and Preparation ---
# This part simulates your data loading.
# In a real scenario, you would load your CSV from a file path.
csv_data = """Date,Price,vader_score
2023-01-01,150.0,0.10
2023-01-02,152.5,0.25
2023-01-03,151.0,-0.15
2023-01-04,155.0,0.50
2023-01-05,157.2,0.65
2023-01-06,156.8,-0.05
"""
for i in range(200):
    prev_price = float(csv_data.strip().split('\n')[-1].split(',')[1])
    new_price = prev_price + np.random.uniform(-2, 2.2)
    new_sentiment = np.random.uniform(-0.5, 0.8)
    csv_data += f"2023-01-{7+i},{new_price:.2f},{new_sentiment:.2f}\n"

# In your real code, you would use:
# df = pd.read_csv("your_data_file.csv")
df = pd.read_csv(io.StringIO(csv_data))
print("Data loaded successfully.")

# --- 2. Feature Engineering ---
n_lags = 3
for lag in range(1, n_lags + 1):
    df[f'sentiment_lag_{lag}'] = df['vader_score'].shift(lag)
    df[f'price_lag_{lag}'] = df['Price'].shift(lag)

df = df.dropna().reset_index(drop=True)
print("Feature engineering complete.")

# --- 3. Model Training ---
X = df[[col for col in df.columns if 'lag' in col]]
y = df['Price']

# Split data to get the training set
split_point = int(len(df) * 0.8)
X_train = X[:split_point]
y_train = y[:split_point]

# Define and train the XGBoost model
model = xgb.XGBRegressor(
    n_estimators=200,
    learning_rate=0.1,
    max_depth=3,
    random_state=42
)

print("Training the model...")
model.fit(X_train, y_train)
print("Model training complete.")

# --- 4. Save the Model ---
model_filename = "xgb_model.json"
model.save_model(model_filename)
print(f"Model saved successfully to {model_filename}")
print("--- Training Script Finished ---")